{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91db147",
   "metadata": {},
   "source": [
    "# Morphological analysis\n",
    "\n",
    "- create list of 50 signs and their synonyms from the course\n",
    "- find a way to group two words into one sign\n",
    "- read about Morphological analysis to make the pairs to solve the problem of verbs & nouns\n",
    "- find way to apply rules like removing  على\n",
    "- find difference between كتب which is book and wrote \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c24473",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "- Grouping\n",
    "- add noun or verb to the list of words we have\n",
    "- suggest similar words (that we already have signs for)\n",
    "- maybe remove the جمع or the مثنى  till i understand when exactly should i use them\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab525c4",
   "metadata": {},
   "source": [
    "# very important\n",
    "\n",
    "- كلمة بيتك وبيتى او اى كلمة فيها ملكية ف وقتها حولها للكلمة الاصلية  اللى هيا هنا هتكون بيت وبعدين اعمل اشارة ملكية او اشارة للمخاطب اللى هيا بتكون انك بتشاور على نفسك او بتشاور امامك وايدك مقفولة\n",
    "- المذكر والمؤنث فى كلمات عديدة يتم باستعمال اشارة الكلمة نفسها تليها اشارة لتحديد المذكر او المؤنث\n",
    "- some words don't follow the previous rule so i have to seperate between the words that follow these rules and the words that don't\n",
    "- اشارة اخت عبارة عن اشارة اخ + اشارة امرأة ونفس الامر لكمات عديدة\n",
    "- فكرة الملكية بنتطبق برضو على الجمع انة اشارة الكلمة وبعدين جمع او لا \n",
    "- مش بحب بتتحول ل بحب لا  ودة بينطبق على كلمات كثير ف حاول تشوف حل لانك تعكس الترتيب دة \n",
    "- بعض الاوقات كلمة الجمع مش بتتحط عشان مش مهمة اوى ف حتى لو الكلمة جمع انت بتعمل اشارة المفرد من غير ما تحط حاجة تبين ان قصدك الجمع ودة بيتفهم من السياق\n",
    "- بعض الاوقات الازمنة مهمة واوقات تانى لا ف مثلا شرب و بشرب وهشرب ممكن يترجموا لنفس الاشارة فى الاخر او ممكن يترجموا ل شرب ماضى او شرب الان او شرب مستقبل واللى بيكون اشارة بتعبر عن الحاجة ووراها اشارة بتعبر عن الزمن\n",
    "- فى لغة الاشارة بتعرف الفاعل من الفعل ان الفاعل بيكون عبارة عن اشارة شخص + اشارة الفعل نفسة"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bf27a",
   "metadata": {},
   "source": [
    "# confusing words so far\n",
    "-  غيرة it could me jealousy or some on else\n",
    "- قلب heart or middle ex : فى قلب الاحداث او قلب انسان\n",
    "- علم flag or science\n",
    "- كتب wrote or books\n",
    "- مركز focus or position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913da07b",
   "metadata": {},
   "source": [
    "# list of classes & methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0241c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json,re\n",
    "\n",
    "class Loader:\n",
    "    ''' this class is used to load signs and letters from json files to python dictionary\n",
    "        any any changes in the logic or file structures should be handled only in this class\n",
    "    '''\n",
    "    def read_json(path):\n",
    "        with open(path, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            return json_data\n",
    "    \n",
    "    def load_multi_file(path=\"\",dic={}):\n",
    "        ''' load json file where the value itself is a dictionary '''\n",
    "        json_data = Loader.read_json(path)\n",
    "        for sign,value in json_data.items():\n",
    "            for word in value['words']:\n",
    "                dic[word] = sign\n",
    "        return dic\n",
    "    \n",
    "    \n",
    "    def load_single_file(path=\"\",dic={}):\n",
    "        ''' load json file where the value is just a word '''\n",
    "        json_data = Loader.read_json(path)\n",
    "        for sign,letter in json_data.items():\n",
    "            dic[letter] = sign\n",
    "        return dic\n",
    "\n",
    "    def load_signs(directory=\"\",word_dic={}):\n",
    "        for file_name in os.listdir(directory):\n",
    "            path = os.path.join(directory,file_name)\n",
    "            Loader.load_multi_file(path,word_dic)\n",
    "        return word_dic\n",
    "            \n",
    "\n",
    "class CustomTest:\n",
    "    ''' this class is made to test the code by having multiple sentence with their output and compare input \n",
    "        with their output\n",
    "        @TODO : i need to change it so it can have list and leave it to user scoring\n",
    "    '''\n",
    "    def __init__(self,path):\n",
    "        ''' func is a function that take list of strings and return the expected array of words '''\n",
    "        self.sentence_list = Loader.read_json(path)[:10] # only first 10 for now\n",
    "        self.func = None \n",
    "        \n",
    "    def compare_list(self,a,b):\n",
    "        if(len(a)!=len(b)):\n",
    "            return False\n",
    "\n",
    "        for i,j in zip(a,b):\n",
    "            if i!=j:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def print_score(self,results,successes,errors):\n",
    "        print(\"succeeds - \",successes)\n",
    "        print(\"failed -  \",errors,\"\\n\")\n",
    "        \n",
    "        for data in results:\n",
    "            print(\"result\",data['result'])\n",
    "            print(\"input\",data['input'])\n",
    "            print(\"expected output\",data['expected_output'])\n",
    "            print(\"my output\",data['actual_output'])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "     \n",
    "\n",
    "        \n",
    "\n",
    "    def run_tests(self):\n",
    "        errors = 0\n",
    "        successes = 0\n",
    "        results = []\n",
    "        for data in self.sentence_list:\n",
    "            output = self.func(data['input'])\n",
    "            cmp = self.compare_list(output,data['output'])\n",
    "            results.append({\n",
    "                \"input\":data[\"input\"],\n",
    "                \"expected_output\":data[\"output\"],\n",
    "                \"actual_output\":output\n",
    "            })\n",
    "            if(cmp):\n",
    "                successes+=1\n",
    "                results[-1]['result'] = \"success\"\n",
    "            else:\n",
    "                errors+=1\n",
    "                results[-1]['result'] = \"fail\"\n",
    "        \n",
    "        self.print_score(results,successes,errors)\n",
    "\n",
    "\n",
    "class Transformer:\n",
    "    ''' this class contains multiple methods & transformation applyed on the text '''\n",
    "    replaced_letters_dic = {\n",
    "    #     \"ة\":\"ه\", #  convert ه to ة\n",
    "        \"أ\":\"ا\",\n",
    "        \"آ\":\"ا\",\n",
    "        \"اّ\":\"ا\",\n",
    "        \"إ\":\"ا\",\n",
    "        \"ى\":\"ي\"\n",
    "    }\n",
    "    \n",
    "    def remove_duplications(text):\n",
    "        p_longation = re.compile(r'(.)\\1+')\n",
    "        subst = r\"\\1\\1\"\n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        text = re.sub(p_longation, subst, text)\n",
    "        text = text.strip().replace(\"  \",\" \")\n",
    "        \n",
    "        text = text.replace('وو', 'و')\n",
    "        text = text.replace('يي', 'ي')\n",
    "        text = text.replace('اا', 'ا')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def replace_letters(text):\n",
    "        # convert list to string to apply the next operations\n",
    "        \n",
    "        for key,value in Transformer.replaced_letters_dic.items():\n",
    "            text = text.replace(key,value)\n",
    "        \n",
    "        return text\n",
    "\n",
    "            \n",
    "    def pipeline(text):\n",
    "        text = Transformer.remove_duplications(text)\n",
    "        text = Transformer.replace_letters(text)\n",
    "        return text.split(\" \")\n",
    "\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c7e989",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f70b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGN_LANGUAGE_DATA_DIRECTORY = \"signLanguageData\"\n",
    "SIGN_LANGUAGE_LETTERS_FILE = \"signLanguageLetters.json\"\n",
    "SENTENCE_PATH = \"sentences.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af5fae",
   "metadata": {},
   "source": [
    "# 1 - load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3c63ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n",
      "32\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "sign_002_33\n",
      "sign_007_7\n",
      "sign_007_7\n"
     ]
    }
   ],
   "source": [
    "word_dic = Loader.load_signs(SIGN_LANGUAGE_DATA_DIRECTORY)\n",
    "letters_dic = Loader.load_single_file(SIGN_LANGUAGE_LETTERS_FILE)\n",
    "                \n",
    "print(len(word_dic))\n",
    "print(len(letters_dic)) \n",
    "\n",
    "# check the dictionay word\n",
    "print(\"سقف\" in word_dic)\n",
    "print(\"سكينة\" in word_dic)\n",
    "print(\"خنزير\" in word_dic)\n",
    "print(\"شماعة\" in word_dic)\n",
    "print(\"طبيب\" in word_dic)\n",
    "print(\"دكتور\" in word_dic)\n",
    "print(\"بطريق\" in word_dic)\n",
    "# view two words with the same sign (synonyms)\n",
    "print(word_dic[\"شماعة\"] )\n",
    "print(word_dic[\"طبيب\"] )\n",
    "print(word_dic[\"دكتور\"] ) # طبيب هى نفس معنى دكتور لذلك لهم نفس الاشارة"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a603aa",
   "metadata": {},
   "source": [
    "# 2 - load sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba93a8c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeds -  1\n",
      "failed -   9 \n",
      "\n",
      "result fail\n",
      "input السلام عليكم ورحمة الله وبركاتة\n",
      "expected output ['سلام', 'عليكم', 'رحمة', 'بركاتة']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result success\n",
      "input انت اسمك اية\n",
      "expected output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input اسمك اية\n",
      "expected output ['اسم', 'ملكك', 'اية']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input كيف حالك\n",
      "expected output ['كيف', 'حال']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input انت عامل اية \n",
      "expected output ['انت', 'عامل', 'اية']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input ازيك\n",
      "expected output ['ازيك']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input ما شاء الله\n",
      "expected output ['ما شاء الله']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input الحمد لله\n",
      "expected output ['الحمد', 'لله']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input انت اصم\n",
      "expected output ['انت', 'اصم']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n",
      "result fail\n",
      "input انا شوفتك من سنة\n",
      "expected output ['انا', 'شوفت', 'انت', 'من', 'سنة']\n",
      "my output ['انت', 'اسم', 'ملكك', 'اية']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that the test word correctly (testing the test class)\n",
    "def test(inp):\n",
    "    return [\"انت\",\"اسم\",\"ملكك\",\"اية\"]\n",
    "\n",
    "test_obj = CustomTest(SENTENCE_PATH)\n",
    "test_obj.func = test\n",
    "\n",
    "test_obj.run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d82d56",
   "metadata": {},
   "source": [
    "# 3 - text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e7146ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['\"صباح', 'الخير', 'ازاي', 'انت', 'عايش\"']\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "s1 = \"\"\"\n",
    "صباااااااح الخير\n",
    "كيف حالك\n",
    "انا احب الشمس  والقمر\n",
    "\"\"\"\n",
    "s2  = \"\"\" \"صبااااااح الخير\\n ازاى انت عايش\" \"\"\"\n",
    "\n",
    "print(Transformer.pipeline(s1))\n",
    "print(Transformer.pipeline(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885550ff",
   "metadata": {},
   "source": [
    "# 4 - root extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819264e8",
   "metadata": {},
   "source": [
    "#### problems\n",
    "- احزانى is converted worng\n",
    "- يكرهون should only be يكرة without adding ون because it's a verb not a noun  \n",
    "- fix the probelm of ة and ه \n",
    "- fix the problem of والقمر to be able to become و القمر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47547823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicRoot:\n",
    "    def __init__(self,word_list):\n",
    "        self.word_list = word_list\n",
    "        self.plural = ['ات',\"ون\",\"ين\",\"ان\"]\n",
    "        self.mine = ['ني',\"تي\"]\n",
    "        \n",
    "\n",
    "        self.pre6 = ['كال',\"بال\",\"فال\",\"مال\",\"ولل\",\"است\",\"يست\",\"تست\",\"مست\",\"وال\"]\n",
    "        self.pre5 = [\"سن\",\"ست\",\"سى\",\"لي\",\"لن\",\"لت\",\"لل\"]\n",
    "        self.pre4 = [\"ت\",\"ي\",\"ب\",\"ل\"]\n",
    "\n",
    "\n",
    "\n",
    "        self.suf5 = [\"ون\",\"ات\",\"ان\",\"ين\",\"تن\",\"تم\",\"كن\",\"كم\",\"هن\",\"هم\",\"يا\",\"ني\",\"تي\",\"وا\",\"ما\",\"نا\",\"ية\",\"ها\",\"اء\"]\n",
    "        self.suf4 = ['ت',\"ة\",\"ا\",\"ي\"]\n",
    "    \n",
    "    def remove_prefix(self,word):\n",
    "        if(len(word)>=6):\n",
    "            for pre in self.pre6:\n",
    "                if word.startswith(pre):\n",
    "                    return word[3:]\n",
    "        if(len(word)>=5):\n",
    "            for pre in self.pre5:\n",
    "                if word.startswith(pre):\n",
    "                    return word[2:]\n",
    "        if(len(word)>=4):\n",
    "            for pre in self.pre4:\n",
    "                if word.startswith(pre):\n",
    "                    return word[1:]\n",
    "        \n",
    "        return word\n",
    "                \n",
    "    def get_extra_words(self,word):\n",
    "        if(len(word)>=5):                \n",
    "            for suf in self.plural:\n",
    "                if word.endswith(suf) and word[:-2] in self.word_list:\n",
    "                    return [word[:-2],\"كثير\"]\n",
    "                \n",
    "        if(word[-1]=='ي' and word[:-1] in self.word_list):\n",
    "            return [word[:-1],\"ملكى\"]\n",
    "        if(word[-1]=='ك' and word[:-1] in self.word_list):\n",
    "            return [word[:-1],\"ملكك\"]\n",
    "        if(word[-1]=='ة' and word[:-1] in self.word_list):\n",
    "            return [word[:-1],\"مؤنث\"]\n",
    "        return []\n",
    "    \n",
    "    def remove_suffix(self,word):        \n",
    "        if(len(word)>=5):                \n",
    "            for suf in self.suf5:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-2]\n",
    "        if(len(word)>=4):\n",
    "            for suf in self.suf4:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-1]\n",
    "        \n",
    "        return word\n",
    "\n",
    "    def clean_word(self,word):\n",
    "        return self.remove_suffix(self.remove_prefix(word))\n",
    "    \n",
    "    def remove_suffix_final(self,word):\n",
    "        output = self.get_extra_words(word)\n",
    "        return output if len(output)>0 else self.remove_suffix(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe8fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ArabicRoot(word_dic)\n",
    "synonyms_dic = {\n",
    "    \"ازيك\" : [\"كيف\",\"حالك\"],\n",
    "    \"و\":\"+\",\n",
    "}\n",
    "\n",
    "def get_synonyms(lis):\n",
    "    final = []\n",
    "    for word in lis:\n",
    "        if word in synonyms_dic:\n",
    "            final.extend(synonyms_dic[word])\n",
    "        else:\n",
    "            final.append(word)\n",
    "    return final\n",
    "\n",
    "def translate(lis):\n",
    "    final = []\n",
    "    for word in lis:\n",
    "        if word in word_dic:\n",
    "            final.append(word)\n",
    "            continue\n",
    "        \n",
    "        if(len(word)>3 and word[:2]==\"ال\"):\n",
    "            word = word[2:]\n",
    "            if word in word_dic:\n",
    "                final.append(word)\n",
    "                continue\n",
    "            \n",
    "        \n",
    "        if(len(word)>=6 and word[:3]==\"وال\"):\n",
    "            word = word[3:]\n",
    "            final.append('+')\n",
    "            if word in word_dic:\n",
    "                final.append(word)\n",
    "                continue\n",
    "        \n",
    "        output = obj.get_extra_words(word)\n",
    "        if(len(output)>0):\n",
    "            final.extend(output)\n",
    "            continue\n",
    "        \n",
    "        final_form = obj.clean_word(word)\n",
    "        if(final_form in word_dic):\n",
    "            final.append(word)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(len(final)>1 and (len(final[-1])==1 and final[-1]!='+' and word!='+') ):\n",
    "            final.append(\" \")\n",
    "        for letter in word:\n",
    "            final.append(letter)\n",
    "        \n",
    "    return final\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_signs(lis):\n",
    "    final =[]\n",
    "    for word in lis:\n",
    "        if len(word)>1:\n",
    "            final.append(word_dic[word])\n",
    "        else:\n",
    "            final.append(letters_dic[word])\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(s):\n",
    "    lis = get_list(s)\n",
    "    print(lis)\n",
    "    \n",
    "    cleaned = clean_str(lis)\n",
    "    print(cleaned)\n",
    "    \n",
    "    synonyms = get_synonyms(cleaned)\n",
    "    print(synonyms)\n",
    "    \n",
    "    translated = translate(synonyms)\n",
    "    print(translated)\n",
    "    \n",
    "    signs = get_signs(translated)    \n",
    "    for sign in signs:\n",
    "        print(sign)\n",
    "    \n",
    "    return signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16c08e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['صبااح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'ش', 'م', 'س', '+', 'ق', 'م', 'ر']\n",
      "sign_012_1\n",
      "sign_001_13\n",
      "sign_001_8\n",
      "sign_001_7\n",
      "sign_001_19\n",
      "sign_001_70\n",
      "sign_000_13\n",
      "sign_000_24\n",
      "sign_000_12\n",
      "sign_000_31\n",
      "sign_000_21\n",
      "sign_000_24\n",
      "sign_000_10\n",
      "\n",
      "\n",
      "['كيف', 'حالك']\n",
      "['كيف', 'حالك']\n",
      "['كيف', 'حالك']\n",
      "['كيف', 'حالك']\n",
      "sign_001_8\n",
      "sign_001_7\n",
      "\n",
      "\n",
      "['قال', 'الخنزير', 'اليوم', 'ملكي']\n",
      "['قال', 'الخنزير', 'اليوم', 'ملكي']\n",
      "['قال', 'الخنزير', 'اليوم', 'ملكي']\n",
      "['قال', 'خنزير', 'يوم', 'ملكي']\n",
      "sign_005_90\n",
      "sign_013_2\n",
      "sign_012_9\n",
      "sign_001_21\n",
      "\n",
      "\n",
      "['الطالب', 'يكرة', 'المدرسة', 'لكن', 'يحب', 'الجامعة']\n",
      "['الطالب', 'يكرة', 'المدرسة', 'لكن', 'يحب', 'الجامعة']\n",
      "['الطالب', 'يكرة', 'المدرسة', 'لكن', 'يحب', 'الجامعة']\n",
      "['طالب', 'ي', 'ك', 'ر', 'ة', 'مدرسة', 'ل', 'ك', 'ن', 'يحب', 'جامعة']\n",
      "sign_007_16\n",
      "sign_000_28\n",
      "sign_000_22\n",
      "sign_000_10\n",
      "sign_000_29\n",
      "sign_004_2\n",
      "sign_000_23\n",
      "sign_000_22\n",
      "sign_000_25\n",
      "sign_001_70\n",
      "sign_004_101\n",
      "\n",
      "\n",
      "['ازيك', 'يا', 'باشا', 'عامل', 'اية']\n",
      "['ازيك', 'يا', 'باشا', 'عامل', 'اية']\n",
      "['كيف', 'حالك', 'يا', 'باشا', 'عامل', 'اية']\n",
      "['كيف', 'حالك', 'ي', 'ا', ' ', 'ب', 'ا', 'ش', 'ا', 'عامل', 'اية']\n",
      "sign_001_8\n",
      "sign_001_7\n",
      "sign_000_28\n",
      "sign_000_1\n",
      "sign_000_32\n",
      "sign_000_2\n",
      "sign_000_1\n",
      "sign_000_13\n",
      "sign_000_1\n",
      "sign_001_7\n",
      "sign_001_8\n",
      "\n",
      "\n",
      "['الحيوانات', 'توجد', 'فى', 'حديقة', 'الحيوانات']\n",
      "['الحيوانات', 'توجد', 'في', 'حديقة', 'الحيوانات']\n",
      "['الحيوانات', 'توجد', 'في', 'حديقة', 'الحيوانات']\n",
      "['حيوانات', 'ت', 'و', 'ج', 'د', 'في', 'حديقة', 'حيوانات']\n",
      "sign_013_1\n",
      "sign_000_3\n",
      "sign_000_27\n",
      "sign_000_5\n",
      "sign_000_8\n",
      "sign_004_87\n",
      "sign_008_23\n",
      "sign_013_1\n",
      "\n",
      "\n",
      "['المهندسون', 'يكرهون', 'الجامعة']\n",
      "['المهندسون', 'يكرهون', 'الجامعة']\n",
      "['المهندسون', 'يكرهون', 'الجامعة']\n",
      "['مهندس', 'كثير', 'يكره', 'كثير', 'جامعة']\n",
      "sign_007_5\n",
      "sign_005_37\n",
      "sign_004_99\n",
      "sign_005_37\n",
      "sign_004_101\n",
      "\n",
      "\n",
      "['الحمد', 'لله']\n",
      "['الحمد', 'لله']\n",
      "['الحمد', 'لله']\n",
      "['الحمد', 'لله']\n",
      "sign_001_9\n",
      "sign_001_5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s =[ \"\"\"\n",
    "صباااااااح الخير\n",
    "كيف حالك\n",
    "انا احب الشمس  والقمر\n",
    "\"\"\",\n",
    "\"كيف حالك\",\n",
    "\"قال الخنزير اليوم ملكي \",\n",
    "\"الطالب يكرة المدرسة لكن يحب الجامعة\",\n",
    "\"ازيك يا باشا عامل اية\",\n",
    "\"الحيوانات توجد فى حديقة الحيوانات\",\n",
    "\"المهندسون يكرهون الجامعة\",\n",
    "\"الحمد لله\"\n",
    "    \n",
    "]\n",
    "for example in s:\n",
    "    output = pipeline(example)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# for sent in sentence_list[:10]:\n",
    "#     s = sent['input']\n",
    "#     pipeline(s)\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2479ff00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.get_extra_words('يكرهون')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b38a0",
   "metadata": {},
   "source": [
    "# 5 - multiple words (grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb09d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign_0 تعارف\n",
      "sign_1 السلام\n",
      "sign_2 عليكم\n",
      "sign_3 رحمه\n",
      "sign_4 الله\n",
      "sign_5 بركاته\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "sign_language_words = os.path.join(\"signLanguageWords\",\"تعارف.txt\")\n",
    "sign_language_data = os.path.join(\"signLanguageData\",\"تعارف.json\")\n",
    "\n",
    "json_data = {}\n",
    "existing_words = {}\n",
    "counter = 0;\n",
    "\n",
    "with open(sign_language_data, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    counter = len(json_data)\n",
    "    for key,value in json_data.items():\n",
    "        existing_words[value['word']] = 1;\n",
    "\n",
    "\n",
    "    \n",
    "with open(sign_language_words,\"r\") as f:\n",
    "    lis = f.read().split(\"\\n\")\n",
    "    \n",
    "    for word in lis:\n",
    "        if(word not in existing_words):\n",
    "            json_data[f'sign_{counter}'] = {\"word\":word}\n",
    "            counter+=1\n",
    "    with open(sign_language_data, 'w') as json_file:\n",
    "        json.dump(json_data,json_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for key,value in json_data.items():\n",
    "    print(key,value['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5b3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(arr):\n",
    "    final = []\n",
    "    for word in arr:\n",
    "        if word in synonyms_table:\n",
    "            final.append(synonyms_table[word])\n",
    "        else:\n",
    "            for letter in word:\n",
    "                final.append(letter)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7109e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['س',\n",
       " 'ل',\n",
       " 'ا',\n",
       " 'م',\n",
       " 'ع',\n",
       " 'ل',\n",
       " 'ى',\n",
       " 'ر',\n",
       " 'ح',\n",
       " 'م',\n",
       " 'ا',\n",
       " 'ل',\n",
       " 'ل',\n",
       " 'ه',\n",
       " 'ب',\n",
       " 'ر',\n",
       " 'ك',\n",
       " 'ة']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex ; we don't have سار but we  have ذهب \n",
    "# we don't have طريق so it spelled it \n",
    "text = clean_str(\"السلام عليكم ورحمه الله وبركاته\")\n",
    "results = lemmatization(text)\n",
    "translate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77168d9",
   "metadata": {},
   "source": [
    "# steaming (might be used in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "71b6c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ac8bea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.isri.html\n",
    "obj = nltk.stem.isri.ISRIStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be295aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خير\n"
     ]
    }
   ],
   "source": [
    "for i in [\"الخير\"]:\n",
    "    print(obj.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "274dfea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نشق\n",
      "حبة\n",
      "رحم\n",
      "ذهب\n",
      "سما\n"
     ]
    }
   ],
   "source": [
    "for i in [\"الاستنشاق\",\"المحبة\",\"الرحمة\",\"يذهب\",\"السما\"]:\n",
    "    print(obj.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "86ac4d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'احز'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.suf32(\"احزان\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d504b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'شتغفار'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.stem(\"اشتغفار\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c55d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
