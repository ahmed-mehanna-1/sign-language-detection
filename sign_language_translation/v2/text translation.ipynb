{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91db147",
   "metadata": {},
   "source": [
    "# Morphological analysis\n",
    "\n",
    "- create list of 50 signs and their synonyms from the course\n",
    "- find a way to group two words into one sign\n",
    "- read about Morphological analysis to make the pairs to solve the problem of verbs & nouns\n",
    "- find way to apply rules like removing  على\n",
    "- find difference between كتب which is book and wrote \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab525c4",
   "metadata": {},
   "source": [
    "# very important\n",
    "\n",
    "- كلمة بيتك وبيتى او اى كلمة فيها ملكية ف وقتها حولها للكلمة الاصلية  اللى هيا هنا هتكون بيت وبعدين اعمل اشارة ملكية او اشارة للمخاطب اللى هيا بتكون انك بتشاور على نفسك او بتشاور امامك وايدك مقفولة\n",
    "- المذكر والمؤنث فى كلمات عديدة يتم باستعمال اشارة الكلمة نفسها تليها اشارة لتحديد المذكر او المؤنث\n",
    "- some words don't follow the previous rule so i have to seperate between the words that follow these rules and the words that don't\n",
    "- اشارة اخت عبارة عن اشارة اخ + اشارة امرأة ونفس الامر لكمات عديدة\n",
    "- فكرة الملكية بنتطبق برضو على الجمع انة اشارة الكلمة وبعدين جمع او لا \n",
    "- مش بحب بتتحول ل بحب لا  ودة بينطبق على كلمات كثير ف حاول تشوف حل لانك تعكس الترتيب دة \n",
    "- بعض الاوقات كلمة الجمع مش بتتحط عشان مش مهمة اوى ف حتى لو الكلمة جمع انت بتعمل اشارة المفرد من غير ما تحط حاجة تبين ان قصدك الجمع ودة بيتفهم من السياق\n",
    "- بعض الاوقات الازمنة مهمة واوقات تانى لا ف مثلا شرب و بشرب وهشرب ممكن يترجموا لنفس الاشارة فى الاخر او ممكن يترجموا ل شرب ماضى او شرب الان او شرب مستقبل واللى بيكون اشارة بتعبر عن الحاجة ووراها اشارة بتعبر عن الزمن\n",
    "- فى لغة الاشارة بتعرف الفاعل من الفعل ان الفاعل بيكون عبارة عن اشارة شخص + اشارة الفعل نفسة"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bf27a",
   "metadata": {},
   "source": [
    "# confusing words so far\n",
    "-  غيرة it could me jealousy or some on else\n",
    "- قلب heart or middle ex : فى قلب الاحداث او قلب انسان\n",
    "- علم flag or science\n",
    "- كتب wrote or books\n",
    "- مركز focus or position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af5fae",
   "metadata": {},
   "source": [
    "# 1 - load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc55c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3c63ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "directory = \"signLanguageData\"\n",
    "word_dic = {}\n",
    "letters_dic = {}\n",
    "\n",
    "for file_name in os.listdir(directory):\n",
    "    path = os.path.join(directory,file_name)\n",
    "    with open(path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        for sign,value in json_data.items():\n",
    "            for word in value['words']:\n",
    "                word_dic[word] = sign\n",
    "\n",
    "with open(\"signLanguageLetters.json\", 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    for sign,letter in json_data.items():\n",
    "        letters_dic[letter] = sign\n",
    "                \n",
    "print(len(word_dic))\n",
    "print(len(letters_dic)) # 29 letter is + used as و "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb73f9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"سقف\" in word_dic)\n",
    "print(\"سكينة\" in word_dic)\n",
    "print(\"خنزير\" in word_dic)\n",
    "print(\"شماعة\" in word_dic)\n",
    "print(\"طبيب\" in word_dic)\n",
    "print(\"دكتور\" in word_dic)\n",
    "print(\"بطريق\" in word_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1cd0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign_002_33\n",
      "sign_007_7\n",
      "sign_007_7\n"
     ]
    }
   ],
   "source": [
    "# view two words with the same sign (synonyms)\n",
    "print(word_dic[\"شماعة\"] )\n",
    "print(word_dic[\"طبيب\"] )\n",
    "print(word_dic[\"دكتور\"] ) # طبيب هى نفس معنى دكتور لذلك لهم نفس الاشارة"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a603aa",
   "metadata": {},
   "source": [
    "# 2 - load sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ba93a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sentences.json\"\n",
    "\n",
    "\n",
    "sign_language_data = os.path.join(\"sentences.json\")\n",
    "\n",
    "sentence_list = None\n",
    "with open(sign_language_data, 'r') as json_file:\n",
    "    sentence_list = json.load(json_file)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "def compare(a,b):\n",
    "    if(len(a)!=len(b)):\n",
    "        return False\n",
    "    \n",
    "    for i,j in zip(a,b):\n",
    "        if i!=j:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def run_tests(func,json_data):\n",
    "    errors = []\n",
    "    successes = []\n",
    "    for data in json_data:\n",
    "        output = func(data['input'])\n",
    "        cmp = compare(output,data['output'])\n",
    "        if(cmp==1):\n",
    "            successes.append({\n",
    "                \"input\":data['input'],\n",
    "                \"output\":data['output'],\n",
    "            })\n",
    "        else:\n",
    "            errors.append({\n",
    "                \"input\":data['input'],\n",
    "                \"output\":data['output'],\n",
    "                \"my_output\":output\n",
    "            })\n",
    "    \n",
    "    if len(errors)>0:\n",
    "        print(\"successfull \",len(successes),\"of\",len(json_data))\n",
    "        for success in successes:\n",
    "            print(success)\n",
    "        print(\"fail\",len(errors))\n",
    "        for error in errors:\n",
    "            print(error)\n",
    "        \n",
    "    else:\n",
    "        print(\"all successfull \",len(successes),\"of\",len(successes))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbcf0639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfull  1 of 5\n",
      "{'input': 'انت اسمك اية', 'output': ['انت', 'اسم', 'ملكك', 'اية']}\n",
      "fail 4\n",
      "{'input': 'السلام عليكم ورحمة الله وبركاتة', 'output': ['سلام', 'عليكم', 'رحمة', 'بركاتة'], 'my_output': ['انت', 'اسم', 'ملكك', 'اية']}\n",
      "{'input': 'اسمك اية', 'output': ['اسم', 'ملكك', 'اية'], 'my_output': ['انت', 'اسم', 'ملكك', 'اية']}\n",
      "{'input': 'كيف حالك', 'output': ['كيف', 'حال'], 'my_output': ['انت', 'اسم', 'ملكك', 'اية']}\n",
      "{'input': 'انت عامل اية ', 'output': ['انت', 'عامل', 'اية'], 'my_output': ['انت', 'اسم', 'ملكك', 'اية']}\n"
     ]
    }
   ],
   "source": [
    "def test(inp):\n",
    "    return [\"انت\",\"اسم\",\"ملكك\",\"اية\"]\n",
    "\n",
    "# first parameter is the function to apply the input on , second parameter is the input string (list of strings)\n",
    "run_tests(test,sentence_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f42c4282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign_001_7'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dic['حالك']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d82d56",
   "metadata": {},
   "source": [
    "# 3 - text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22540a",
   "metadata": {},
   "source": [
    "### 3.1 split by words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ac9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string to list of words\n",
    "def get_list(text):\n",
    "    # remove longation\n",
    "    p_longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(p_longation, subst, text)\n",
    "    text = text.strip().replace(\"  \",\" \")\n",
    "    \n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99bb4cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['صبااح', 'الخير', 'ازاى', 'انت', 'عايش']\n",
      "['صبااح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "صباااااااح الخير\n",
    "كيف حالك\n",
    "انا احب الشمس  والقمر\n",
    "\"\"\"\n",
    "print(get_list(\"صبااااااح الخير\\n ازاى انت عايش\"))\n",
    "print(get_list(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5a4bb",
   "metadata": {},
   "source": [
    "### 3.2 - remove or replace specific letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7839c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove repeated letters ا & ى & و\n",
    "# other transformations\n",
    "\n",
    "replacing = {\n",
    "#     \"ة\":\"ه\", #  convert ه to ة\n",
    "    \"أ\":\"ا\",\n",
    "    \"آ\":\"ا\",\n",
    "    \"اّ\":\"ا\",\n",
    "    \"إ\":\"ا\",\n",
    "    \"ى\":\"ي\"\n",
    "}\n",
    "\n",
    "\n",
    "def replace_letters(text):\n",
    "    for key,value in replacing.items():\n",
    "        text = text.replace(key,value)\n",
    "    \n",
    "    \n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "    return text\n",
    "\n",
    "\n",
    "# remove ال\n",
    "def clean_str(text):\n",
    "    # convert list to string to apply the next operations\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    text = replace_letters(text)\n",
    "    \n",
    "    text = text.split(\" \")\n",
    "    \n",
    "    # add this processing into other place\n",
    "    final = []\n",
    "    for i,word in enumerate(text):\n",
    "        final.append(word)\n",
    "    \n",
    "    return final\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885550ff",
   "metadata": {},
   "source": [
    "# 4 - root extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819264e8",
   "metadata": {},
   "source": [
    "#### problems\n",
    "- احزانى is converted worng\n",
    "- يكرهون should only be يكرة without adding ون because it's a verb not a noun  \n",
    "- fix the probelm of ة and ه \n",
    "- fix the problem of والقمر to be able to become و القمر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47547823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArabicRoot:\n",
    "    def __init__(self,word_list):\n",
    "        self.word_list = word_list\n",
    "        self.plural = ['ات',\"ون\",\"ين\",\"ان\"]\n",
    "        self.mine = ['ني',\"تي\"]\n",
    "        \n",
    "\n",
    "        self.pre6 = ['كال',\"بال\",\"فال\",\"مال\",\"ولل\",\"است\",\"يست\",\"تست\",\"مست\",\"وال\"]\n",
    "        self.pre5 = [\"سن\",\"ست\",\"سى\",\"لي\",\"لن\",\"لت\",\"لل\"]\n",
    "        self.pre4 = [\"ت\",\"ي\",\"ب\",\"ل\"]\n",
    "\n",
    "\n",
    "\n",
    "        self.suf5 = [\"ون\",\"ات\",\"ان\",\"ين\",\"تن\",\"تم\",\"كن\",\"كم\",\"هن\",\"هم\",\"يا\",\"ني\",\"تي\",\"وا\",\"ما\",\"نا\",\"ية\",\"ها\",\"اء\"]\n",
    "        self.suf4 = ['ت',\"ة\",\"ا\",\"ي\"]\n",
    "    \n",
    "    def remove_prefix(self,word):\n",
    "        if(len(word)>=6):\n",
    "            for pre in self.pre6:\n",
    "                if word.startswith(pre):\n",
    "                    return word[3:]\n",
    "        if(len(word)>=5):\n",
    "            for pre in self.pre5:\n",
    "                if word.startswith(pre):\n",
    "                    return word[2:]\n",
    "        if(len(word)>=4):\n",
    "            for pre in self.pre4:\n",
    "                if word.startswith(pre):\n",
    "                    return word[1:]\n",
    "        \n",
    "        return word\n",
    "                \n",
    "    def get_extra_words(self,word):\n",
    "        if(len(word)>=5):                \n",
    "            for suf in self.plural:\n",
    "                if word.endswith(suf) and word[:-2] in self.word_list:\n",
    "                    return [word[:-2],\"كثير\"]\n",
    "                \n",
    "        if(word[-1]=='ي' and word[:-1] in self.word_list):\n",
    "            return [word[:-1],\"ملكى\"]\n",
    "        if(word[-1]=='ك' and word[:-1] in self.word_list):\n",
    "            return [word[:-1],\"ملكك\"]\n",
    "        if(word[-1]=='ة' and word[:-1] in self.word_list):\n",
    "            return [word[:-1],\"مؤنث\"]\n",
    "        return []\n",
    "    \n",
    "    def remove_suffix(self,word):        \n",
    "        if(len(word)>=5):                \n",
    "            for suf in self.suf5:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-2]\n",
    "        if(len(word)>=4):\n",
    "            for suf in self.suf4:\n",
    "                if word.endswith(suf):\n",
    "                    return word[:-1]\n",
    "        \n",
    "        return word\n",
    "\n",
    "    def clean_word(self,word):\n",
    "        return self.remove_suffix(self.remove_prefix(word))\n",
    "    \n",
    "    def remove_suffix_final(self,word):\n",
    "        output = self.get_extra_words(word)\n",
    "        return output if len(output)>0 else self.remove_suffix(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afe8fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ArabicRoot(word_dic)\n",
    "synonyms_dic = {\n",
    "    \"ازيك\" : [\"كيف\",\"حالك\"],\n",
    "    \"و\":\"+\",\n",
    "}\n",
    "\n",
    "def get_synonyms(lis):\n",
    "    final = []\n",
    "    for word in lis:\n",
    "        if word in synonyms_dic:\n",
    "            final.extend(synonyms_dic[word])\n",
    "        else:\n",
    "            final.append(word)\n",
    "    return final\n",
    "\n",
    "def translate(lis):\n",
    "    final = []\n",
    "    for word in lis:\n",
    "        if word in word_dic:\n",
    "            final.append(word)\n",
    "            continue\n",
    "        \n",
    "        if(len(word)>3 and word[:2]==\"ال\"):\n",
    "            word = word[2:]\n",
    "            if word in word_dic:\n",
    "                final.append(word)\n",
    "                continue\n",
    "            \n",
    "        \n",
    "        if(len(word)>=6 and word[:3]==\"وال\"):\n",
    "            word = word[3:]\n",
    "            final.append('+')\n",
    "            if word in word_dic:\n",
    "                final.append(word)\n",
    "                continue\n",
    "        \n",
    "        output = obj.get_extra_words(word)\n",
    "        if(len(output)>0):\n",
    "            final.extend(output)\n",
    "            continue\n",
    "        \n",
    "        final_form = obj.clean_word(word)\n",
    "        if(final_form in word_dic):\n",
    "            final.append(word)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(len(final)>1 and (len(final[-1])==1 and final[-1]!='+' and word!='+') ):\n",
    "            final.append(\" \")\n",
    "        for letter in word:\n",
    "            final.append(letter)\n",
    "        \n",
    "    return final\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_signs(lis):\n",
    "    final =[]\n",
    "    for word in lis:\n",
    "        if len(word)>1:\n",
    "            final.append(word_dic[word])\n",
    "        else:\n",
    "            final.append(letters_dic[word])\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "def pipeline(s):\n",
    "    lis = get_list(s)\n",
    "    print(lis)\n",
    "    \n",
    "    cleaned = clean_str(lis)\n",
    "    print(cleaned)\n",
    "    \n",
    "    synonyms = get_synonyms(cleaned)\n",
    "    print(synonyms)\n",
    "    \n",
    "    translated = translate(synonyms)\n",
    "    print(translated)\n",
    "    \n",
    "    signs = get_signs(translated)    \n",
    "    for sign in signs:\n",
    "        print(sign)\n",
    "    \n",
    "    return signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16c08e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['صبااح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'الشمس', 'والقمر']\n",
      "['صباح', 'الخير', 'كيف', 'حالك', 'انا', 'احب', 'ش', 'م', 'س', '+', 'ق', 'م', 'ر']\n",
      "sign_012_1\n",
      "sign_001_13\n",
      "sign_001_8\n",
      "sign_001_7\n",
      "sign_001_19\n",
      "sign_001_70\n",
      "sign_000_13\n",
      "sign_000_24\n",
      "sign_000_12\n",
      "sign_000_31\n",
      "sign_000_21\n",
      "sign_000_24\n",
      "sign_000_10\n",
      "\n",
      "\n",
      "['كيف', 'حالك']\n",
      "['كيف', 'حالك']\n",
      "['كيف', 'حالك']\n",
      "['كيف', 'حالك']\n",
      "sign_001_8\n",
      "sign_001_7\n",
      "\n",
      "\n",
      "['قال', 'الخنزير', 'اليوم', 'ملكي']\n",
      "['قال', 'الخنزير', 'اليوم', 'ملكي']\n",
      "['قال', 'الخنزير', 'اليوم', 'ملكي']\n",
      "['قال', 'خنزير', 'يوم', 'ملكي']\n",
      "sign_005_90\n",
      "sign_013_2\n",
      "sign_012_9\n",
      "sign_001_21\n",
      "\n",
      "\n",
      "['الطالب', 'يكرة', 'المدرسة', 'لكن', 'يحب', 'الجامعة']\n",
      "['الطالب', 'يكرة', 'المدرسة', 'لكن', 'يحب', 'الجامعة']\n",
      "['الطالب', 'يكرة', 'المدرسة', 'لكن', 'يحب', 'الجامعة']\n",
      "['طالب', 'ي', 'ك', 'ر', 'ة', 'مدرسة', 'ل', 'ك', 'ن', 'يحب', 'جامعة']\n",
      "sign_007_16\n",
      "sign_000_28\n",
      "sign_000_22\n",
      "sign_000_10\n",
      "sign_000_29\n",
      "sign_004_2\n",
      "sign_000_23\n",
      "sign_000_22\n",
      "sign_000_25\n",
      "sign_001_70\n",
      "sign_004_101\n",
      "\n",
      "\n",
      "['ازيك', 'يا', 'باشا', 'عامل', 'اية']\n",
      "['ازيك', 'يا', 'باشا', 'عامل', 'اية']\n",
      "['كيف', 'حالك', 'يا', 'باشا', 'عامل', 'اية']\n",
      "['كيف', 'حالك', 'ي', 'ا', ' ', 'ب', 'ا', 'ش', 'ا', 'عامل', 'اية']\n",
      "sign_001_8\n",
      "sign_001_7\n",
      "sign_000_28\n",
      "sign_000_1\n",
      "sign_000_32\n",
      "sign_000_2\n",
      "sign_000_1\n",
      "sign_000_13\n",
      "sign_000_1\n",
      "sign_001_7\n",
      "sign_001_8\n",
      "\n",
      "\n",
      "['الحيوانات', 'توجد', 'فى', 'حديقة', 'الحيوانات']\n",
      "['الحيوانات', 'توجد', 'في', 'حديقة', 'الحيوانات']\n",
      "['الحيوانات', 'توجد', 'في', 'حديقة', 'الحيوانات']\n",
      "['حيوانات', 'ت', 'و', 'ج', 'د', 'في', 'حديقة', 'حيوانات']\n",
      "sign_013_1\n",
      "sign_000_3\n",
      "sign_000_27\n",
      "sign_000_5\n",
      "sign_000_8\n",
      "sign_004_87\n",
      "sign_008_23\n",
      "sign_013_1\n",
      "\n",
      "\n",
      "['المهندسون', 'يكرهون', 'الجامعة']\n",
      "['المهندسون', 'يكرهون', 'الجامعة']\n",
      "['المهندسون', 'يكرهون', 'الجامعة']\n",
      "['مهندس', 'كثير', 'يكره', 'كثير', 'جامعة']\n",
      "sign_007_5\n",
      "sign_005_37\n",
      "sign_004_99\n",
      "sign_005_37\n",
      "sign_004_101\n",
      "\n",
      "\n",
      "['الحمد', 'لله']\n",
      "['الحمد', 'لله']\n",
      "['الحمد', 'لله']\n",
      "['الحمد', 'لله']\n",
      "sign_001_9\n",
      "sign_001_5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s =[ \"\"\"\n",
    "صباااااااح الخير\n",
    "كيف حالك\n",
    "انا احب الشمس  والقمر\n",
    "\"\"\",\n",
    "\"كيف حالك\",\n",
    "\"قال الخنزير اليوم ملكي \",\n",
    "\"الطالب يكرة المدرسة لكن يحب الجامعة\",\n",
    "\"ازيك يا باشا عامل اية\",\n",
    "\"الحيوانات توجد فى حديقة الحيوانات\",\n",
    "\"المهندسون يكرهون الجامعة\",\n",
    "\"الحمد لله\"\n",
    "    \n",
    "]\n",
    "for example in s:\n",
    "    output = pipeline(example)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# for sent in sentence_list[:10]:\n",
    "#     s = sent['input']\n",
    "#     pipeline(s)\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2479ff00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.get_extra_words('يكرهون')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b38a0",
   "metadata": {},
   "source": [
    "# 5 - multiple words (grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb09d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign_0 تعارف\n",
      "sign_1 السلام\n",
      "sign_2 عليكم\n",
      "sign_3 رحمه\n",
      "sign_4 الله\n",
      "sign_5 بركاته\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "sign_language_words = os.path.join(\"signLanguageWords\",\"تعارف.txt\")\n",
    "sign_language_data = os.path.join(\"signLanguageData\",\"تعارف.json\")\n",
    "\n",
    "json_data = {}\n",
    "existing_words = {}\n",
    "counter = 0;\n",
    "\n",
    "with open(sign_language_data, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "    counter = len(json_data)\n",
    "    for key,value in json_data.items():\n",
    "        existing_words[value['word']] = 1;\n",
    "\n",
    "\n",
    "    \n",
    "with open(sign_language_words,\"r\") as f:\n",
    "    lis = f.read().split(\"\\n\")\n",
    "    \n",
    "    for word in lis:\n",
    "        if(word not in existing_words):\n",
    "            json_data[f'sign_{counter}'] = {\"word\":word}\n",
    "            counter+=1\n",
    "    with open(sign_language_data, 'w') as json_file:\n",
    "        json.dump(json_data,json_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for key,value in json_data.items():\n",
    "    print(key,value['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5b3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(arr):\n",
    "    final = []\n",
    "    for word in arr:\n",
    "        if word in synonyms_table:\n",
    "            final.append(synonyms_table[word])\n",
    "        else:\n",
    "            for letter in word:\n",
    "                final.append(letter)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7109e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['س',\n",
       " 'ل',\n",
       " 'ا',\n",
       " 'م',\n",
       " 'ع',\n",
       " 'ل',\n",
       " 'ى',\n",
       " 'ر',\n",
       " 'ح',\n",
       " 'م',\n",
       " 'ا',\n",
       " 'ل',\n",
       " 'ل',\n",
       " 'ه',\n",
       " 'ب',\n",
       " 'ر',\n",
       " 'ك',\n",
       " 'ة']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ex ; we don't have سار but we  have ذهب \n",
    "# we don't have طريق so it spelled it \n",
    "text = clean_str(\"السلام عليكم ورحمه الله وبركاته\")\n",
    "results = lemmatization(text)\n",
    "translate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77168d9",
   "metadata": {},
   "source": [
    "# steaming (might be used in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "71b6c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ac8bea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.isri.html\n",
    "obj = nltk.stem.isri.ISRIStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be295aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خير\n"
     ]
    }
   ],
   "source": [
    "for i in [\"الخير\"]:\n",
    "    print(obj.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "274dfea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نشق\n",
      "حبة\n",
      "رحم\n",
      "ذهب\n",
      "سما\n"
     ]
    }
   ],
   "source": [
    "for i in [\"الاستنشاق\",\"المحبة\",\"الرحمة\",\"يذهب\",\"السما\"]:\n",
    "    print(obj.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "86ac4d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'احز'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.suf32(\"احزان\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d504b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'شتغفار'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.stem(\"اشتغفار\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c55d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
