{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc46c896",
   "metadata": {},
   "source": [
    "# process text with videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b29ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "02ed3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"../../data/one_video\")\n",
    "letters_path = os.path.join(\"../../data/letters\")\n",
    "\n",
    "def get_list_of_actions(data_path):\n",
    "    lis = os.listdir(data_path)\n",
    "    output = {}\n",
    "    for i in lis:\n",
    "        key = i.split('.')[0].split(\"_\")[-1]\n",
    "        output[key] = os.path.join(data_path,i)\n",
    "    return output\n",
    "\n",
    "def get_list_of_letters(data_path):\n",
    "    lis = os.listdir(data_path)\n",
    "    output = {}\n",
    "    for i in lis:\n",
    "        key = i.split('.')[0]\n",
    "        output[key] = os.path.join(data_path,i)\n",
    "    return output\n",
    "\n",
    "\n",
    "    \n",
    "actions = get_list_of_actions(data_path)\n",
    "letters = get_list_of_letters(letters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03991208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text(image,text,position,size='l'):\n",
    "    if size=='l':\n",
    "        cv2.putText(image, text, position, \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "    elif size=='s':\n",
    "        cv2.putText(image, text, position, \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "04b0c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letters(word):\n",
    "    output = []\n",
    "    for letter in word:\n",
    "        video = cv2.VideoCapture(letters[letter.upper()])\n",
    "        video_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "        count=0\n",
    "        while video.isOpened():\n",
    "            ret,frame = video.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            output.append(frame)\n",
    "            count+=1\n",
    "            if(count>=video_length):\n",
    "                video.release()\n",
    "        video.release()\n",
    "    return output\n",
    "\n",
    "\n",
    "# text = \"orange tea\"\n",
    "def create_video(words):\n",
    "    list_of_frames = []\n",
    "    for word in words:\n",
    "        if word in actions:\n",
    "            vid = []\n",
    "            video = cv2.VideoCapture(actions[word])\n",
    "            video_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "\n",
    "            count=0\n",
    "            while video.isOpened():\n",
    "                ret,frame = video.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                vid.append(frame)\n",
    "                count+=1\n",
    "                if(count>=video_length):\n",
    "                    video.release()\n",
    "            video.release()\n",
    "            list_of_frames.append(vid)\n",
    "        else:\n",
    "            list_of_frames.append(get_letters(word))\n",
    "    \n",
    "    return list_of_frames\n",
    "    \n",
    "\n",
    "    \n",
    "def display_video(words,video):\n",
    "    cv2.imshow(\"current frame\",np.zeros((500,500)))\n",
    "    if cv2.waitKey(0) & 0xFF == ord('s'):\n",
    "        pass\n",
    "    \n",
    "    list_of_viewed_words = []\n",
    "    \n",
    "    for i,word in enumerate(words):\n",
    "        if(len(video[i])>0):\n",
    "            list_of_viewed_words.append(word)\n",
    "        for frame in video[i]:\n",
    "            \n",
    "            cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "            write_text(frame,\" \".join(list_of_viewed_words[-5:]),(10,30))\n",
    "            cv2.imshow(\"current frame\",frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dfe41db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"fuck you\".split(\" \")\n",
    "video = create_video(words)\n",
    "display_video(words,video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "59315562",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b97a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lis=[1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1750511",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# process text with keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b13fd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c912e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model here is holistic surrounding the code\n",
    "def mediapipe_detection(image,model):\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results\n",
    "    \n",
    "\n",
    "def draw_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    \n",
    "def draw_styled_landmarks(image,results):\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    \n",
    "    \n",
    "def draw_styled_landmarks(image,results):\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def extract_keypoints(results):\n",
    "    # extract pose marks\n",
    "    if results.pose_landmarks:\n",
    "        pose = np.array([ [res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark ]).flatten()\n",
    "    else:\n",
    "        pose = np.zeros(num_pose_marks*4)\n",
    "    \n",
    "    # extract left hand\n",
    "    if results.left_hand_landmarks:\n",
    "        left_hand = np.array([ [res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark ]).flatten()\n",
    "    else:\n",
    "        left_hand = np.zeros(num_hand_marks*3)\n",
    "        \n",
    "        \n",
    "    # extract right hand\n",
    "    if results.right_hand_landmarks:\n",
    "        right_hand = np.array([ [res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark ]).flatten()\n",
    "    else:\n",
    "        right_hand = np.zeros(num_hand_marks*3)\n",
    "    \n",
    "    return np.concatenate([pose,left_hand,right_hand])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "29212380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letters(word):\n",
    "    output = []\n",
    "    for letter in word:\n",
    "        video = cv2.VideoCapture(letters[letter.upper()])\n",
    "        video_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "        count=0\n",
    "        while video.isOpened():\n",
    "            ret,frame = video.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            output.append(frame)\n",
    "            count+=1\n",
    "            if(count>=video_length):\n",
    "                video.release()\n",
    "        video.release()\n",
    "    return output\n",
    "\n",
    "\n",
    "# text = \"orange tea\"\n",
    "def create_video(words):\n",
    "    list_of_frames = []\n",
    "    for word in words:\n",
    "        if word in actions:\n",
    "            vid = []\n",
    "            video = cv2.VideoCapture(actions[word])\n",
    "            video_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "\n",
    "            count=0\n",
    "            while video.isOpened():\n",
    "                ret,frame = video.read()\n",
    "                if not ret:\n",
    "                    continue\n",
    "                vid.append(frame)\n",
    "                count+=1\n",
    "                if(count>=video_length):\n",
    "                    video.release()\n",
    "            video.release()\n",
    "            list_of_frames.append(vid)\n",
    "        else:\n",
    "            list_of_frames.append(get_letters(word))\n",
    "    \n",
    "    return list_of_frames\n",
    "    \n",
    "\n",
    "    \n",
    "def display_keypoints_video(words,video):\n",
    "    cv2.imshow(\"current frame\",np.zeros((500,500)))\n",
    "    if cv2.waitKey(0) & 0xFF == ord('s'):\n",
    "        pass\n",
    "    \n",
    "    list_of_viewed_words = []\n",
    "    holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) \n",
    "    for i,word in enumerate(words):\n",
    "        if(len(video[i])>0):\n",
    "            list_of_viewed_words.append(word)\n",
    "        for frame in video[i]:\n",
    "            frame = cv2.resize(frame,(1280,960))\n",
    "            frame, results = mediapipe_detection(frame, holistic)\n",
    "            new_frame = np.zeros((960,1280,3)) + 255\n",
    "            draw_styled_landmarks(new_frame, results)\n",
    "            cv2.rectangle(new_frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "            write_text(new_frame,\" \".join(list_of_viewed_words[-5:]),(10,30))\n",
    "            cv2.imshow(\"current frame\",new_frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "52e3309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"fuck you\".split(\" \")\n",
    "video = create_video(words)\n",
    "display_keypoints_video(words,video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
