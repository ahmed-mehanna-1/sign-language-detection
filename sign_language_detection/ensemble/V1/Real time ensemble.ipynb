{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92366306",
   "metadata": {},
   "source": [
    "# globals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe291ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "actions = ['sister','hurry','hungry','meal','brother','tree','heavy','cry','family','wise']\n",
    "colors = [\n",
    "    (245,117,16),\n",
    "    (117,245,16),\n",
    "    (16,117,245)\n",
    "]\n",
    "\n",
    "def softmax(x):    \n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "def arg_max(array):\n",
    "    arg_max = np.argmax(array)\n",
    "    return arg_max,array[arg_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79c5e0",
   "metadata": {},
   "source": [
    "# pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd2ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_relu_to_swish(model: nn.Module):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, nn.ReLU):\n",
    "            setattr(model, child_name, nn.SiLU(True))\n",
    "        else:\n",
    "            convert_relu_to_swish(child)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "class Swish(nn.Module):\n",
    "    def __init(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.mult_(torch.sigmoid(x))\n",
    "    \n",
    "    \n",
    "    \n",
    "class r2plus1d_18(nn.Module):\n",
    "    def __init__(self, pretrained=True, n_classes=3, dropout_p=0.5):\n",
    "        super(r2plus1d_18, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        model = torchvision.models.video.r2plus1d_18(pretrained=self.pretrained)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.r2plus1d_18 = nn.Sequential(*modules)\n",
    "        convert_relu_to_swish(self.r2plus1d_18)\n",
    "        self.fc1 = nn.Linear(model.fc.in_features, self.n_classes)\n",
    "        self.dropout = nn.Dropout(dropout_p, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (b, f, c, h, w) = x.size()\n",
    "        # x = x.view(b, c, f, h, w)\n",
    "\n",
    "        out = self.r2plus1d_18(x)\n",
    "        out = out.flatten(1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "h, w = 128, 128\n",
    "mean = [0.43216, 0.394666, 0.37645]\n",
    "std = [0.22803, 0.22145, 0.216989]\n",
    "\n",
    "\n",
    "\n",
    "pytorch_model = r2plus1d_18(pretrained=False, n_classes=n_classes)\n",
    "best_checkpoint = torch.load(\"pytorch_weights.tar\")\n",
    "pytorch_model.load_state_dict(best_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pytorch_model = pytorch_model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df37573",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform   = transforms.Resize((h, w))\n",
    "totensor_transform  = transforms.ToTensor()\n",
    "normalize_transform = transforms.Normalize(mean, std)\n",
    "\n",
    "class PytorchPredictor:\n",
    "    def __init__(self,model,device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.sequence = []\n",
    "        \n",
    "    \n",
    "    def can_predict(self):\n",
    "        return len(self.sequence) == 16\n",
    "    \n",
    "    def add_frame(self,frame):\n",
    "        \n",
    "        new_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        new_frame = Image.fromarray(new_frame)\n",
    "        new_frame = resize_transform(new_frame)\n",
    "        new_frame = totensor_transform(new_frame)\n",
    "        new_frame = normalize_transform(new_frame).to(self.device)\n",
    "        \n",
    "        self.sequence.append(new_frame)\n",
    "        self.sequence = self.sequence[-16:]\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        seq = torch.stack(self.sequence).to(self.device)\n",
    "        seq = torch.unsqueeze(seq, dim=0).permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            res = self.model(seq)\n",
    "            res = res.cpu().detach().numpy()[0]\n",
    "            return softmax(res)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eeff50",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b356f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800872b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 15:11:50.486843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:50.487227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:50.487419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:50.487654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:50.487845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:50.488019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 1318 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1be7822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 15:11:57.932349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:57.932778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:57.933087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:57.933458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:57.933785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-13 15:11:57.934065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 1318 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e82d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "holistic = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "num_hand_marks = 21\n",
    "num_pose_marks = 33\n",
    "\n",
    "\n",
    "pose_selected_landmarks = [\n",
    "    [0,2,5,11,13,15,12,14,16],\n",
    "    [0,2,4,5,8,9,12,13,16,17,20],\n",
    "    [0,2,4,5,8,9,12,13,16,17,20],\n",
    "]\n",
    "\n",
    "def draw_updated_styled(image,results):\n",
    "    image_rows, image_cols, _ = image.shape\n",
    "    \n",
    "    original_landmarks = [\n",
    "        results.pose_landmarks,\n",
    "        results.left_hand_landmarks,\n",
    "        results.right_hand_landmarks\n",
    "    ]\n",
    "\n",
    "    \n",
    "    for shape in range(3):\n",
    "        if(original_landmarks[shape]):\n",
    "            lis = original_landmarks[shape].landmark\n",
    "            for idx in pose_selected_landmarks[shape]:\n",
    "                point = lis[idx]\n",
    "                landmark_px = mp_drawing._normalized_to_pixel_coordinates(point.x, point.y,\n",
    "                                                           image_cols, image_rows)\n",
    "\n",
    "                cv2.circle(image, landmark_px, 2, (0,0,255),\n",
    "                         4)     \n",
    "                \n",
    "def extract_keypoints(results):\n",
    "    \n",
    "    original_landmarks = [\n",
    "        results.pose_landmarks,\n",
    "        results.left_hand_landmarks,\n",
    "        results.right_hand_landmarks\n",
    "    ]\n",
    "    \n",
    "    outputs = []\n",
    "    for shape in range(3):\n",
    "        if(original_landmarks[shape]):\n",
    "            lis = original_landmarks[shape].landmark\n",
    "            pose = np.array([ [lis[res].x,lis[res].y] for res in pose_selected_landmarks[shape] ]).flatten()\n",
    "        else:\n",
    "            pose = np.zeros(len(pose_selected_landmarks[shape])*2)\n",
    "        outputs.append(pose)\n",
    "    return np.concatenate([outputs[0],outputs[1],outputs[2]])\n",
    "\n",
    "\n",
    "\n",
    "# holistic model process image and return the results as keypoints\n",
    "def mediapipe_detection(image,model):\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image  = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def draw_landmark_from_array(image,keyPoints):\n",
    "    image_rows, image_cols, _ = image.shape\n",
    "    \n",
    "    \n",
    "    for i in range(len(keyPoints)//2):\n",
    "        x = keyPoints[i*2]\n",
    "        y = keyPoints[i*2+1]\n",
    "        if(x!=0 and y!=0): \n",
    "            landmark_px = mp_drawing._normalized_to_pixel_coordinates(x,y,\n",
    "                                                       image_cols, image_rows)\n",
    "            cv2.circle(image, landmark_px, 2, (0,0,255),\n",
    "                     4)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8766b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Input,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    input_layer = Input(shape=(16,62))\n",
    "    layer = LSTM(64,return_sequences=True,activation=\"relu\")(input_layer)\n",
    "    layer = LSTM(128,return_sequences=True,activation=\"relu\")(layer)\n",
    "    layer = LSTM(96,return_sequences=False,activation=\"relu\")(layer)\n",
    "    layer = Dense(64,activation=\"relu\")(layer)\n",
    "    layer = Dense(len(actions),activation=\"softmax\")(layer)\n",
    "\n",
    "    \n",
    "    model = Model(inputs=input_layer,outputs=layer)\n",
    "    model.compile(optimizer=\"Adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "keras_weights_dir = os.path.join(\"keras_weights\")\n",
    "best_model_file_name = os.path.join(keras_weights_dir,\"V1.h5\")\n",
    "keras_model = get_model()\n",
    "keras_model.load_weights(os.path.join(best_model_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e6af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasPredictor:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.sequence = []\n",
    "        \n",
    "    \n",
    "    def can_predict(self):\n",
    "        return len(self.sequence) == 16\n",
    "    \n",
    "    def add_frame(self,frame):\n",
    "        \n",
    "        f2 = cv2.resize(frame,(512,512))\n",
    "        image, results = mediapipe_detection(f2, holistic)\n",
    "        keypoints = extract_keypoints(results)\n",
    "        \n",
    "        self.sequence.append(keypoints)\n",
    "        self.sequence = self.sequence[-16:]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        return self.model.predict(np.expand_dims(self.sequence, axis=0))[0]\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72265bc",
   "metadata": {},
   "source": [
    "# Real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e003615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    l = len(colors)\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        prob = max(0,prob)\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100)*5, 90+num*40), colors[num%l], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0affa790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pytorch_predictor = PytorchPredictor(model=pytorch_model,device=device)\n",
    "keras_predictor = KerasPredictor(model=keras_model)\n",
    "\n",
    "\n",
    "\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Read feed\n",
    "    ret, frame = cap.read()\n",
    "    if(not ret):\n",
    "        break\n",
    "\n",
    "    pytorch_predictor.add_frame(frame)\n",
    "    keras_predictor.add_frame(frame)\n",
    "    \n",
    "\n",
    "    arg_max=-1\n",
    "    #if pytorch_predictor.can_predict() and keras_predictor.can_predict():\n",
    "    if pytorch_predictor.can_predict() :   \n",
    "        res1 = pytorch_predictor.predict()\n",
    "        res2 = keras_predictor.predict()\n",
    "        res = res1 + res2\n",
    "        # res = res1 \n",
    "            \n",
    "        arg_max = np.argmax(res)\n",
    "            \n",
    "            \n",
    "        predictions.append(arg_max)\n",
    "\n",
    "\n",
    "    #3. Viz logic\n",
    "        if np.unique(predictions[-2:])[0]==arg_max: \n",
    "            if res[arg_max] > threshold: \n",
    "\n",
    "                if len(sentence) > 0: \n",
    "                    if actions[arg_max] != sentence[-1]:\n",
    "                        sentence.append(actions[arg_max])\n",
    "                else:\n",
    "                    sentence.append(actions[arg_max])\n",
    "\n",
    "        if len(sentence) > 5: \n",
    "            sentence = sentence[-5:]\n",
    "\n",
    "        # Viz probabilities\n",
    "        frame = prob_viz(res, actions, frame, colors)\n",
    "\n",
    "    cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "    cv2.putText(frame, ' '.join(sentence), (3,30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Show to screen\n",
    "    \n",
    "    cv2.imshow('OpenCV Feed', frame)\n",
    "\n",
    "    # Break gracefully\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9aeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next line to clear nvidia ca\n",
    "sudo rm -rf ~/.nv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b241ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7db59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
