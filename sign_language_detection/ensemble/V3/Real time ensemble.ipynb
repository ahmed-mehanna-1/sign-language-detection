{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92366306",
   "metadata": {},
   "source": [
    "# globals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe291ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# utils\n",
    "from utils import actions,arg_max\n",
    "\n",
    "# models & realTime\n",
    "from pytorch_model import PytorchPredictor\n",
    "from keras_model import KerasPredictor\n",
    "from MultiSignDetector import MultiSignPredictor\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "n_classes = len(actions)\n",
    "\n",
    "WEIGHTS_PATH=os.path.join(\"..\",\"V1\")\n",
    "KERAS_WEIGHTS_PATH = os.path.join(WEIGHTS_PATH,\"keras_weights\",\"V1.h5\")\n",
    "TORCH_WEIGHTS_PATH = os.path.join(WEIGHTS_PATH,\"pytorch_weights.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79c5e0",
   "metadata": {},
   "source": [
    "# pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df37573",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_predictor = PytorchPredictor(path=TORCH_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eeff50",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b356f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 19:17:38.447745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-10 19:17:38.448787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-10 19:17:38.449014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-10 19:17:38.449186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-10 19:17:38.449345: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-10 19:17:38.449506: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-10 19:17:38.449662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mina/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-03-10 19:17:38.450133: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-10 19:17:38.451408: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-10 19:17:38.453895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-10 19:17:38.454589: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-10 19:17:38.455311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-10 19:17:38.456001: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "keras_predictor = KerasPredictor(path=KERAS_WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93674779",
   "metadata": {},
   "source": [
    "# MultiSign Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed4fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "holistic = mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "fsize = (512,512)\n",
    "\n",
    "multi_sign_detector = MultiSignPredictor(holistic, fsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594b0e8",
   "metadata": {},
   "source": [
    "# Predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14485b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                            ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                            ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                            )     \n",
    "\n",
    "def display_sentence(frame,sentence):\n",
    "    cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "    cv2.putText(frame, ' '.join(sentence), (3,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def dispay_probability(frame,data):\n",
    "    TEXT_COLOR = (0,0,255)\n",
    "    \n",
    "    cv2.putText(frame, \"L:\"+str(data[\"L\"]), (0, 85+0*40), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2, cv2.LINE_8)\n",
    "    cv2.putText(frame, \"R:\"+str(data[\"R\"]), (0, 85+1*40), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2, cv2.LINE_8)\n",
    "\n",
    "    cv2.putText(frame, \"L2:\"+str(data[\"L2\"]), (0, 85+4*40), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2, cv2.LINE_8)\n",
    "    cv2.putText(frame, \"R2:\"+str(data[\"R2\"]), (0, 85+5*40), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2, cv2.LINE_8)\n",
    "\n",
    "\n",
    "    cv2.putText(frame, \"L-D:\"+str(data[\"L-D\"]), (0, 85+8*40), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2, cv2.LINE_8)\n",
    "    cv2.putText(frame, \"R-D:\"+str(data[\"R-D\"]), (0, 85+9*40), cv2.FONT_HERSHEY_SIMPLEX, 1, TEXT_COLOR, 2, cv2.LINE_8)\n",
    "\n",
    "\n",
    "def display_counters(frame,counter,discarded_frames):\n",
    "    cv2.putText(frame, str(counter), (250, 85+5*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (100,250,150), 2, cv2.LINE_8)\n",
    "    cv2.putText(frame, str(discarded_frames), (250, 85+6*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (100,250,150), 2, cv2.LINE_8)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "sentence = []\n",
    "predictions = []\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "discarded_frames = 0\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Read feed\n",
    "    ret, frame = cap.read()\n",
    "    if(not ret):\n",
    "        break\n",
    "    \n",
    "    frame,body_keypoints = multi_sign_detector.detect_frame(frame)\n",
    "    \n",
    "\n",
    "    if multi_sign_detector.have_sign(frame):\n",
    "        frame_list = multi_sign_detector.get_frames_indices(frames_no=16)\n",
    "\n",
    "        for frame_idx in frame_list:\n",
    "            pytorch_predictor.add_frame(multi_sign_detector[frame_idx])\n",
    "            keras_predictor.add_frame(multi_sign_detector[frame_idx])\n",
    "\n",
    "        res1 = pytorch_predictor.predict()\n",
    "        res2 = keras_predictor.predict()\n",
    "        res = res1 + res2\n",
    "        arg_max = np.argmax(res)\n",
    "        predictions.append(arg_max)\n",
    "        predictions = predictions[-16:]\n",
    "        print(predictions)\n",
    "        multi_sign_detector.truncate_listed_frames()\n",
    "        sentence.append(actions[arg_max])\n",
    "        sentence = sentence[-4:]\n",
    "\n",
    "\n",
    "    image = frame.copy()\n",
    "    draw_styled_landmarks(image, body_keypoints)\n",
    "    display_sentence(image,sentence)\n",
    "    dispay_probability(image,multi_sign_detector.get_data())\n",
    "    display_counters(image,multi_sign_detector.counter,multi_sign_detector.discarded_frames)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Real-Time\", image)\n",
    "\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071ab9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fa732",
   "metadata": {},
   "source": [
    "# Create Custom Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055bb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "frames_per_seconds = 15\n",
    "\n",
    "out = cv2.VideoWriter(f'main2.mp4',0x7634706d, frames_per_seconds, (512,512))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame,(512,512))\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Real-Time\", frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39003630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39db53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04717328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
