{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b34f2c",
   "metadata": {},
   "source": [
    "### the model performing bad because the nature of the training data is different from the test data\n",
    "the training contains random images from classes to be classified as 0\n",
    "the validation and test contains random images from other classes so some of them the model has never seen before\n",
    "\n",
    "\n",
    "## future approach\n",
    "- [ ] update extract keypoints function to extract fewer keypoints\n",
    "- [ ] try with 20 frames and 32 frames and 60 frames\n",
    "- [ ] read more about machine learning to understand why this is falling \n",
    "- [ ] read more about one vs many and how to work with data \n",
    "- [ ] change loss function to focus more on not picking signs \n",
    "- [ ] change optimizer and use lr scheduler\n",
    "- [ ] use data augemntation\n",
    "- [ ] for the 0 class get random different data each epoch\n",
    "- [ ] change binary crossentropy to sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c03c2d",
   "metadata": {},
   "source": [
    "# 1 - install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bffa97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c02b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..','..'))) # .. should point to the Utils directory location\n",
    "from Utils.poseEstimation import mediapipe_detection,draw_styled_landmarks,extract_keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a53451",
   "metadata": {},
   "source": [
    "# Move them to utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce1f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath = os.path.join(\"..\",\"..\",\"data\",\"Datasets\")\n",
    "n_actions = 20\n",
    "\n",
    "\n",
    "# this function responsible for loading 4 labels files train,validation,test,class_id\n",
    "# input -> main_dir , output->dictionary containig 4 pandas DataFrames\n",
    "def load_csv_labels(data_path):\n",
    "    train_labels = pd.read_csv(os.path.join(data_path,\"train_labels.csv\"),names=['sample','id'])\n",
    "    validation_labels = pd.read_csv(os.path.join(data_path,\"validation_labels.csv\"),names=['sample','id'])\n",
    "    test_labels = pd.read_csv(os.path.join(data_path,\"test_labels.csv\"),names=['sample','id'])\n",
    "    class_id = pd.read_csv(os.path.join(data_path,\"class_id.csv\"))\n",
    "    \n",
    "    return {\"train\":train_labels,\"val\":validation_labels,\"test\":test_labels},class_id\n",
    "\n",
    "# check if file exists or not input -> full path , output : boolean\n",
    "def check_file_exists(file_path):\n",
    "    try:\n",
    "        f = open(file_path)\n",
    "        f.close()\n",
    "        return True\n",
    "    except IOError:\n",
    "        return False\n",
    "\n",
    "# take main_dir,label(train,val,test),file_name and create full path\n",
    "def get_full_path(data_path,label,file_path):\n",
    "    return os.path.join(data_path,label,file_path+\"_color.mp4\")\n",
    "\n",
    "# input -> number of actions and DataFrame of class_id and return list of n actions with their labels as dictionary\n",
    "def get_actions_names(n_actions,class_id):\n",
    "    n_actions = 20\n",
    "    actions = list(class_id['EN'][:n_actions])\n",
    "    dic={}\n",
    "    for i,action in enumerate(actions):\n",
    "        dic[action]=i\n",
    "    \n",
    "    return actions,dic\n",
    "\n",
    "\n",
    "# take id and label and load all data from it as array of full pathes and labels (the array of only this id)\n",
    "def get_data_id(action_id,labels,label='train',desired_label=None):\n",
    "    if(not desired_label):\n",
    "        desired_label = action_id\n",
    "        \n",
    "    label_dic = labels[label]\n",
    "    data =  label_dic[label_dic['id']==action_id]\n",
    "    lis =  [get_full_path(DataPath,label,file_name) for file_name in  (data['sample'])]\n",
    "    data =  [i for i in lis if check_file_exists(i)]\n",
    "    return data,[desired_label for i in data]\n",
    "\n",
    "# same as the previous one except it loads all data except the one with this id\n",
    "def get_data_nid(action_id,labels,label,max_samples=150,desired_label=0):\n",
    "    label_dic = labels[label]\n",
    "    data = label_dic[label_dic['id']!=action_id]\n",
    "    lis =  [get_full_path(DataPath,label,file_name) for file_name in  (data['sample'])]\n",
    "    data =  [i for i in lis[:max_samples] if check_file_exists(i)]\n",
    "    return data,[desired_label for i in data]\n",
    "\n",
    "\n",
    "def create_trainig_validation_test_data(n_actions,labels):\n",
    "    names = list(labels.keys())\n",
    "\n",
    "    X_Data  = []\n",
    "    Y_Data  = []\n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        temp_x = []\n",
    "        temp_y = []\n",
    "        for i in range(n_actions):\n",
    "            x,y = get_data_id(i,labels,name)\n",
    "            temp_x.extend(x)\n",
    "            temp_y.extend(y)\n",
    "        X_Data.append(temp_x)\n",
    "        Y_Data.append(temp_x)\n",
    "\n",
    "        \n",
    "    return X_Data[0],Y_Data[0],X_Data[1],Y_Data[1],X_Data[2],Y_Data[2]\n",
    "\n",
    "\n",
    "def create_trainig_validation_test_data_binary(action_id,labels,desired_label):\n",
    "    names = list(labels.keys())\n",
    "\n",
    "    X_Data  = []\n",
    "    Y_Data  = []\n",
    "\n",
    "    for i,name in enumerate(names):\n",
    "        x,y = get_data_id(action_id,labels,name,desired_label=1)\n",
    "        x2,y2 = get_data_nid(action_id,labels,name,desired_label=0)\n",
    "        x.extend(x2)\n",
    "        y.extend(y2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        X_Data.append(x)\n",
    "        Y_Data.append(y)\n",
    "\n",
    "        \n",
    "    return X_Data[0],Y_Data[0],X_Data[1],Y_Data[1],X_Data[2],Y_Data[2]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a26a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "labels,class_id  = load_csv_labels(DataPath)\n",
    "\n",
    "\n",
    "actions,dic = get_actions_names(n_actions,class_id)\n",
    "\n",
    "# train_X,train_Y,val_X,val_Y,test_X,test_Y = create_trainig_validation_test_data(n_actions,labels)\n",
    "train_X,train_Y,val_X,val_Y,test_X,test_Y = create_trainig_validation_test_data_binary(0,labels,desired_label=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee58a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 276 170 170 166 166\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X),len(train_Y),len(val_X),len(val_Y),len(test_X),len(test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781311b",
   "metadata": {},
   "source": [
    "### 3.2 process videos into frames and label to cateogries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d602a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frames(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    video_length = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "    # count = 0\n",
    "    # frame_rate = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    count=0\n",
    "    frames = []\n",
    "    while video.isOpened():\n",
    "      # frame_id = video.get(0)\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        if not ret:\n",
    "            continue\n",
    "        frames.append(frame)\n",
    "        count += 1\n",
    "        # If there are no more frames left\n",
    "        if (count > (video_length-1)):\n",
    "          # Release the feed\n",
    "          video.release()\n",
    "        # if frame_id % math.floor(1) == 0:\n",
    "        #     file_name = f\"{video_path}_frame_{count}.jpg\"\n",
    "        #     count += 1\n",
    "        #     # print(f\"File name: {file_name}\")\n",
    "        #     frames.append(frame)\n",
    "        #     # cv2.imwrite(file_name, frame)\n",
    "    video.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def get_frames(video_path,num_frames):\n",
    "    frames = capture_frames(video_path)\n",
    "    video_length = len(frames)\n",
    "    steps = video_length/num_frames\n",
    "    count=0\n",
    "    new_frames=[]\n",
    "    while count<video_length:\n",
    "        frame = frames[int(count)]\n",
    "        new_frames.append(frame)\n",
    "        count+=steps\n",
    "\n",
    "    s = np.array(new_frames[:num_frames])\n",
    "    return np.array(new_frames[:num_frames])\n",
    "\n",
    "\n",
    "def extract_keypoints_video(path,i=-1):\n",
    "    \n",
    "    if(i):\n",
    "        print(i+\" \"*20,end=\"\\r\")\n",
    "    frames = get_frames(path,25)\n",
    "    output_key_points=[]\n",
    "    with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for frame in frames:\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            output_key_points.append(extract_keypoints(results))\n",
    "    return np.array(output_key_points)\n",
    "\n",
    "\n",
    "def extract_and_save(data,file_path):\n",
    "    if file_path in os.listdir():\n",
    "        return np.load(file_path)\n",
    "    else:\n",
    "        x =  np.array([extract_keypoints_video(path,f'Saving in {file_path} iteration : {i+1}/{len(data)}') for i,path in enumerate(data) ])\n",
    "        np.save(file_path,x)\n",
    "        return x\n",
    "\n",
    "def save_if_not_exists(data,file_path):\n",
    "    if file_path in os.listdir():\n",
    "        return np.load(file_path)\n",
    "    else:\n",
    "        np.save(file_path,data)\n",
    "        return np.array(data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4424e1",
   "metadata": {},
   "source": [
    "### 3.3 - extract the keypoints and save them as npy or load them if they are exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b5ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = extract_and_save(train_X,\"train_X.npy\")\n",
    "val_X   = extract_and_save(val_X,\"val_X.npy\")\n",
    "test_X  = extract_and_save(test_X,\"test_X.npy\")\n",
    "\n",
    "train_Y = save_if_not_exists(np.array(train_Y),\"train_Y.npy\")\n",
    "val_Y   = save_if_not_exists(np.array(val_Y),\"val_Y.npy\")\n",
    "test_Y  = save_if_not_exists(np.array(test_Y),\"test_Y.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a8b3604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 276 170 170 166 166\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X),len(train_Y),len(val_X),len(val_Y),len(test_X),len(test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64a5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.permutation(len(train_X))\n",
    "train_X = train_X[x]\n",
    "train_Y = train_Y[x]\n",
    "x = np.random.permutation(len(val_X))\n",
    "val_X = val_X[x]\n",
    "val_Y = val_Y[x]\n",
    "x = np.random.permutation(len(test_X))\n",
    "test_X = test_X[x]\n",
    "test_Y = test_Y[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59fd806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276 276 170 170 166 166\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X),len(train_Y),len(val_X),len(val_Y),len(test_X),len(test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742a5d4",
   "metadata": {},
   "source": [
    "# 4 - build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c15994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfdeb079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(25,258))\n",
    "layer = LSTM(32,return_sequences=True,activation=\"relu\")(input_layer)\n",
    "layer = LSTM(64,return_sequences=False,activation=\"relu\")(layer)\n",
    "layer = Dense(64,activation=\"relu\")(layer)\n",
    "layer = Dense(32,activation=\"relu\")(layer)\n",
    "layer = Dense(1,activation=\"sigmoid\")(layer)\n",
    "\n",
    "model = Model(inputs=input_layer,outputs=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "330f87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 25, 258)]         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 25, 32)            37248     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,353\n",
      "Trainable params: 68,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874d4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a38fd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 2s 67ms/step - loss: 0.6286 - binary_accuracy: 0.7065 - val_loss: 0.6369 - val_binary_accuracy: 0.6235\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5317 - binary_accuracy: 0.7246 - val_loss: 0.4930 - val_binary_accuracy: 0.9059\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4245 - binary_accuracy: 0.8623 - val_loss: 1.1674 - val_binary_accuracy: 0.4176\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3696 - binary_accuracy: 0.8551 - val_loss: 1.5727 - val_binary_accuracy: 0.1059\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2958 - binary_accuracy: 0.8949 - val_loss: 1.4922 - val_binary_accuracy: 0.3706\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2287 - binary_accuracy: 0.9203 - val_loss: 0.6217 - val_binary_accuracy: 0.7118\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.7453 - binary_accuracy: 0.7464 - val_loss: 0.4478 - val_binary_accuracy: 0.8824\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.6068 - binary_accuracy: 0.6087 - val_loss: 0.6525 - val_binary_accuracy: 0.8706\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.5029 - binary_accuracy: 0.7246 - val_loss: 0.6789 - val_binary_accuracy: 0.5118\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3710 - binary_accuracy: 0.8841 - val_loss: 2.8941 - val_binary_accuracy: 0.1235\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2532 - binary_accuracy: 0.9022 - val_loss: 1.3861 - val_binary_accuracy: 0.3176\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2640 - binary_accuracy: 0.8986 - val_loss: 4.4910 - val_binary_accuracy: 0.1588\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4356 - binary_accuracy: 0.8225 - val_loss: 0.8039 - val_binary_accuracy: 0.3647\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4129 - binary_accuracy: 0.9203 - val_loss: 0.8287 - val_binary_accuracy: 0.2706\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3226 - binary_accuracy: 0.8841 - val_loss: 4.6322 - val_binary_accuracy: 0.1059\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2478 - binary_accuracy: 0.8949 - val_loss: 1.1899 - val_binary_accuracy: 0.1706\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2265 - binary_accuracy: 0.9420 - val_loss: 1.6854 - val_binary_accuracy: 0.2118\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2020 - binary_accuracy: 0.9457 - val_loss: 2.5656 - val_binary_accuracy: 0.1529\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2016 - binary_accuracy: 0.9420 - val_loss: 2.9608 - val_binary_accuracy: 0.1529\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1725 - binary_accuracy: 0.9457 - val_loss: 2.4526 - val_binary_accuracy: 0.2118\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1429 - binary_accuracy: 0.9638 - val_loss: 2.3596 - val_binary_accuracy: 0.2471\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2181 - binary_accuracy: 0.9203 - val_loss: 1.9414 - val_binary_accuracy: 0.3294\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2142 - binary_accuracy: 0.9348 - val_loss: 1.6213 - val_binary_accuracy: 0.3706\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1681 - binary_accuracy: 0.9420 - val_loss: 2.0202 - val_binary_accuracy: 0.2529\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1348 - binary_accuracy: 0.9565 - val_loss: 3.2633 - val_binary_accuracy: 0.1765\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1208 - binary_accuracy: 0.9601 - val_loss: 2.8593 - val_binary_accuracy: 0.2824\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1278 - binary_accuracy: 0.9638 - val_loss: 3.4841 - val_binary_accuracy: 0.2118\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1187 - binary_accuracy: 0.9674 - val_loss: 5.0707 - val_binary_accuracy: 0.1882\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1203 - binary_accuracy: 0.9638 - val_loss: 4.7279 - val_binary_accuracy: 0.1706\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1068 - binary_accuracy: 0.9710 - val_loss: 5.3569 - val_binary_accuracy: 0.2059\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1323 - binary_accuracy: 0.9601 - val_loss: 2.6057 - val_binary_accuracy: 0.3059\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1071 - binary_accuracy: 0.9710 - val_loss: 4.6067 - val_binary_accuracy: 0.2000\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0983 - binary_accuracy: 0.9674 - val_loss: 3.9432 - val_binary_accuracy: 0.3000\n",
      "Epoch 34/200\n",
      "3/9 [=========>....................] - ETA: 0s - loss: 0.1457 - binary_accuracy: 0.9479"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_92900/3610315942.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=200, callbacks=[tb_callback],validation_data=(val_X,val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "006a7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cb9dffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ad1bc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape = (-1,6450)\n",
    "val_X.shape = (-1,6450)\n",
    "test_X.shape = (-1,6450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "91ebe542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.23529411764705882\n",
      "0.13253012048192772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mina/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(train_X, train_Y)\n",
    "\n",
    "print(clf.score(train_X, train_Y))\n",
    "print(clf.score(val_X, val_Y))\n",
    "print(clf.score(test_X, test_Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dcccb9",
   "metadata": {},
   "source": [
    "# 5 - Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "75b9084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape = (-1,25,258)\n",
    "val_X.shape = (-1,25,258)\n",
    "test_X.shape = (-1,25,258)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c43c817",
   "metadata": {},
   "source": [
    "### this doesn't make any sence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8a1059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 8.4343 - binary_accuracy: 0.1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.434293746948242, 0.10240963846445084]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cad1b4",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4f1e0f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 20,   0],\n",
       "        [139,  11]],\n",
       "\n",
       "       [[ 11, 139],\n",
       "        [  0,  20]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score,plot_confusion_matrix\n",
    "\n",
    "yhat = model.predict(val_X)\n",
    "# ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "#yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "multilabel_confusion_matrix(val_Y, yhat.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "84940445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99988556] 0\n",
      "[0.99930036] 0\n",
      "[0.9642273] 0\n",
      "[0.9993154] 0\n",
      "[0.9998085] 0\n",
      "[0.7735257] 0\n",
      "[0.99989057] 0\n",
      "[0.9998754] 0\n",
      "[0.99961984] 0\n",
      "[0.7913579] 0\n",
      "[0.9974141] 0\n",
      "[0.99890935] 0\n",
      "[0.952731] 0\n",
      "[0.99667335] 0\n",
      "[0.9997353] 0\n",
      "[0.99817073] 0\n",
      "[0.99983644] 0\n",
      "[0.9997334] 0\n",
      "[0.99978095] 0\n",
      "[0.9912566] 0\n",
      "[0.9998524] 0\n",
      "[0.84857273] 0\n",
      "[0.9997689] 0\n",
      "[0.9976794] 0\n",
      "[0.98566055] 0\n",
      "[0.9999031] 0\n",
      "[0.9994234] 0\n",
      "[0.99890506] 0\n",
      "[0.99978834] 0\n",
      "[0.9997713] 0\n",
      "[0.99995995] 0\n",
      "[0.9977958] 0\n",
      "[0.9982834] 0\n",
      "[0.99965656] 0\n",
      "[0.99978286] 0\n",
      "[0.9991611] 0\n",
      "[0.9998036] 0\n",
      "[0.9992513] 0\n",
      "[0.99787617] 0\n",
      "[0.9996979] 0\n",
      "[0.9115199] 0\n",
      "[0.99982834] 0\n",
      "[0.99982494] 0\n",
      "[0.99979144] 0\n",
      "[0.99243647] 0\n",
      "[0.9959235] 0\n",
      "[0.86173433] 0\n",
      "[0.9986154] 0\n",
      "[0.99976116] 0\n",
      "[0.98479164] 0\n",
      "[0.99989605] 0\n",
      "[0.99900705] 0\n",
      "[0.99982786] 0\n",
      "[0.9997954] 0\n",
      "[0.99935585] 0\n",
      "[0.9871301] 0\n",
      "[0.9992724] 0\n",
      "[0.9993381] 0\n",
      "[0.99968004] 0\n",
      "[0.99991953] 0\n",
      "[0.99917954] 0\n",
      "[0.9996544] 0\n",
      "[0.9998778] 0\n",
      "[0.9959329] 0\n",
      "[0.94264627] 0\n",
      "[0.99973756] 0\n",
      "[0.9998772] 0\n",
      "[0.74445236] 0\n",
      "[0.99324083] 0\n",
      "[0.9993604] 0\n",
      "[0.9997002] 0\n",
      "[0.9999155] 0\n",
      "[0.99621236] 0\n",
      "[0.9998442] 0\n",
      "[0.99964833] 0\n",
      "[0.9991673] 0\n",
      "[0.99919575] 0\n",
      "[0.99968886] 0\n",
      "[0.9998914] 0\n",
      "[0.9995308] 0\n",
      "[0.8518403] 0\n",
      "[0.999816] 0\n",
      "[0.9849333] 0\n",
      "[0.9986945] 0\n",
      "[0.9998418] 0\n",
      "[0.99285215] 0\n",
      "[0.999928] 0\n",
      "[0.9999342] 0\n",
      "[0.9974261] 0\n",
      "[0.99638015] 0\n",
      "[0.9998679] 0\n",
      "[0.9959176] 0\n",
      "[0.99982685] 0\n",
      "[0.9997973] 0\n",
      "[0.99976057] 0\n",
      "[0.9997464] 0\n",
      "[0.9916191] 0\n",
      "[0.9997814] 0\n",
      "[0.99977344] 0\n",
      "[0.9976422] 0\n",
      "[0.99886453] 0\n",
      "[0.9988846] 0\n",
      "[0.94605815] 0\n",
      "[0.9998318] 0\n",
      "[0.99918455] 0\n",
      "[0.9995278] 0\n",
      "[0.9966943] 0\n",
      "[0.9997733] 0\n",
      "[0.9998512] 0\n",
      "[0.99946696] 0\n",
      "[0.9978727] 0\n",
      "[0.9997986] 0\n",
      "[0.99967074] 0\n",
      "[0.76896363] 0\n",
      "[0.99935323] 0\n",
      "[0.99988484] 0\n",
      "[0.99981457] 0\n",
      "[0.99985385] 0\n",
      "[0.99957746] 0\n",
      "[0.99991786] 0\n",
      "[0.999358] 0\n",
      "[0.99989927] 0\n",
      "[0.9988795] 0\n",
      "[0.9919155] 0\n",
      "[0.9930102] 0\n",
      "[0.9994295] 0\n",
      "[0.9830115] 0\n",
      "[0.8891281] 0\n",
      "[0.99985385] 0\n",
      "[0.99834657] 0\n",
      "[0.99927324] 0\n",
      "[0.99127114] 0\n",
      "[0.99441516] 0\n",
      "[0.9965784] 0\n",
      "[0.99984884] 0\n",
      "[0.72621036] 0\n",
      "[0.9992817] 0\n",
      "[0.9990125] 0\n",
      "[0.9994023] 0\n",
      "[0.9998348] 0\n",
      "[0.9998375] 0\n",
      "[0.99962187] 0\n",
      "[0.9985942] 0\n",
      "[0.999589] 0\n",
      "[0.97300625] 0\n",
      "[0.98295975] 0\n",
      "[0.99962294] 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(yhat)):\n",
    "    print(yhat[i],val_Y[i]) if yhat[i].round() != val_Y[i] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b7497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24844b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88f40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c1bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7743e09c",
   "metadata": {},
   "source": [
    "# 6 - test in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ad45443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a888db6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp.solutions.holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "        if(not ret):\n",
    "            break\n",
    "    \n",
    "        frame = cv2.resize(frame,(512,512))\n",
    "    \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-25:]\n",
    "        \n",
    "        if len(sequence) == 25:\n",
    "            x = np.expand_dims(sequence, axis=0)\n",
    "#             x.shape = (1,25*258)\n",
    "#             res = clf.predict(x)\n",
    "#             print(res)\n",
    "            # print(x.shape)\n",
    "            res = model.predict(x)[0][0] # res is now number between 0 and 1 where 1 mean sign\n",
    "    \n",
    "            predictions.append(res.round())\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, str(res), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "844aa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04f084c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba788c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
